# ğŸ§  VGG-16 (Very Deep Convolutional Networks for Large-Scale Image Recognition, 2014)

This folder contains a reproduction of the **VGG-16** model from the influential paper:

> **Very Deep Convolutional Networks for Large-Scale Image Recognition**  
> by K. Simonyan & A. Zisserman  
> Published by Visual Geometry Group (VGG), University of Oxford, 2014

---

## ğŸ”— Links

- ğŸ“„ **Paper**: [arXiv:1409.1556](https://arxiv.org/abs/1409.1556)
- âœï¸ **My Review**: [Paper Review](https://dotz0ver.tistory.com/50)
- ğŸ§ª **Implementation Notebook**: `Vision/VGG/vgg16.ipynb`

---

## ğŸ“ Description

This implementation reproduces the **VGG-16** architecture using the **Tiny ImageNet** dataset for training and evaluation.  
VGG-16 is known for its **depth** (16 learnable layers) and **simplicity**â€”relying only on 3Ã—3 convolution filters and 2Ã—2 max pooling layers.

---

## ğŸ§  Model Architecture

- **Input**: 224Ã—224 RGB image  
- **Conv Layers**: 13  
- **FC Layers**: 3  
- **Activation**: ReLU  
- **Kernel Size**: 3Ã—3, stride=1, padding=1 (same padding)  
- **Pooling**: 2Ã—2 Max Pooling, stride=2 (after conv blocks 1~5)  
- **LRN**: âŒ Not used  
- **Dropout**: âœ… Applied to FC layers (p=0.5)  

---

## âš™ï¸ Training & Optimization

- **Dataset**: Tiny ImageNet (200 classes)  
- **Batch Size**: 128 _(original: 256)_  
- **Epochs**: 20  
- **Loss**: CrossEntropyLoss  
- **Optimizer**: SGD  
  - Learning rate: 0.01  
  - Momentum: 0.9  
  - Weight decay: 5Ã—10â»â´  
- **Learning Rate Scheduler**: ReduceLROnPlateau (â†“LR if val loss plateaus)

---

## ğŸ§ª Data Augmentation

**Training Transformations**
- Resize â†’ 256  
- Random Crop â†’ 224Ã—224  
- Random Horizontal Flip  
- Color Jitter (brightness, contrast, saturation, hue)  
- Normalization (Tiny ImageNet RGB Mean/Std)

**Validation / Test Transformations**
- Resize â†’ 224  
- Center Crop â†’ 224Ã—224  
- Normalization
